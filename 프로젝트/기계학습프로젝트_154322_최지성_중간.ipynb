{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fas_train = pd.read_csv('archive/fashion-mnist_train.csv')\n",
    "fas_test = pd.read_csv('archive/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ln 3 to ln 7 : https://www.kaggle.com/egenaz/fashion-mnist-modeling-w-randomforestclassifier 부분 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idx2numpy in c:\\anaconda\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from idx2numpy) (1.20.1)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from idx2numpy) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install idx2numpy\n",
    "import idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'archive/t10k-images-idx3-ubyte'\n",
    "array = idx2numpy.convert_from_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM2klEQVR4nO3dX6xV9ZnG8eeRAxopKmhEBmRgkLu5oIZodHRSM7ZxuBB60Um5oplJDhfD2N7VtCYlaZrUybTjXRMaTRnTSpqolTSTaf3TYG9sOBhHsEjRSttTjpwY/AcxocDbi7NoTvGs3zrsvddeW97vJ9nZe693r7VfVnjOXn/2Xj9HhABc/q7ougEAw0HYgSQIO5AEYQeSIOxAEmPDfDPbHPoHWhYRnmt6X5/stu+zfcT2G7Yf7GdZANrlXs+z214g6TeSPitpUtJ+SVsj4teFefhkB1rWxif7bZLeiIjfRsQZSXskbe5jeQBa1E/YV0r6w6znk9W0v2J73PaE7Yk+3gtAn/o5QDfXpsLHNtMjYpekXRKb8UCX+vlkn5R086znqyQd768dAG3pJ+z7Ja23vdb2IklflLR3MG0BGLSeN+Mj4qztHZJ+JmmBpMci4rWBdQZgoHo+9dbTm7HPDrSulS/VAPjkIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0fP47JJk+5ikDyWdk3Q2IjYOoikAg9dX2Cv3RMQ7A1gOgBaxGQ8k0W/YQ9LPbR+wPT7XC2yP256wPdHnewHogyOi95ntv4mI47ZvlPSspP+IiBcLr+/9zQDMS0R4rul9fbJHxPHqflrS05Ju62d5ANrTc9htL7a95MJjSZ+TdGhQjQEYrH6Oxi+X9LTtC8v5UUT830C6AjBwfe2zX/Kbsc8OtK6VfXYAnxyEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQaw277MdvTtg/NmrbM9rO2j1b3S9ttE0C/5vPJ/gNJ91007UFJz0fEeknPV88BjLDGsEfEi5JOXjR5s6Td1ePdkrYMti0AgzbW43zLI2JKkiJiyvaNdS+0PS5pvMf3ATAgvYZ93iJil6RdkmQ72n4/AHPr9Wj8CdsrJKm6nx5cSwDa0GvY90raVj3eJumZwbQDoC2OKG9Z235C0mck3SDphKRvSPqJpB9LWi3p95K+EBEXH8Sba1mX5Wb89ddfX6yvXbu2WF+8eHGxvnr16mL94MGDtbXt27cX53388ceL9ePHjxfr77//frH+7rvvFuslV1xR/iw6f/58z8tuYrtYb8pNlyJizuYb99kjYmtN6Z/66gjAUPENOiAJwg4kQdiBJAg7kARhB5Jo/Rt0F2s6pVHSz+mOBQsWFOvnzp0r1u+5557a2gMPPFCcd926dcX61VdfXayfOXOmWH/zzTdrazfddFNx3n379hXrO3bsKNbvvffeYv3++++vrb300kvFefs9tbZo0aLaWtM6HeVTa73ikx1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmj8ietA38yO0nn2Nn/S2PTvvPXWW4v1nTt31taOHDlSnPfAgQPF+sTERLHe9DPSTZs21dbuuOOO4ry33HJLsX7q1Klivek7BKWf/7711lvFeR9++OFife/evcV6VnU/ceWTHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSGPp59qG92SVqWg+l88UnTzZeRfsTa82aNcX6Qw89VKxv2LChtlb6vbkknT59uljfs2dPsT41NVVbW7ZsWXHepusuNH0npOn6CaXlL1y4sDjvCy+8UFt7/fXXdfr0ac6zA5kRdiAJwg4kQdiBJAg7kARhB5Ig7EASQ71u/MKFC7V8+fLa+vr164vzf/TRRz3VpObrwj/yyCPF+pVXXllbu/POO4vzXnvttcX6VVddVaw3nY8unfO9/fbbi/M2XVf+gw8+KNabfsv/3HPP1daOHj1anHdycrJY37JlS7F+991319aa/l1nz54t1pvOs4+NlaNVmv+6664rzrt///6eltv4yW77MdvTtg/NmrbT9h9tv1Ld6q+eAGAkzGcz/geS7ptj+n9HxIbq9r+DbQvAoDWGPSJelHT5fh8USKKfA3Q7bL9abeYvrXuR7XHbE7Yn+h27C0Dveg379yStk7RB0pSk79S9MCJ2RcTGiNjYdFADQHt6Sl9EnIiIcxFxXtL3Jd022LYADFpPYbe9YtbTz0s6VPdaAKOh8ffstp+Q9BlJN0g6Iekb1fMNkkLSMUnbI6L+x8OVsbGxWLJkSW296RrnpXP0q1atKs7bdJ797bffLtZXrlxZrJeUztFLzWOFN127fXp6urbWdG32pnrpN+Gj7pprrqmtNZ1HbzpP3qTp9/BN9ZL33nuvWK+7bnzjvygits4x+dF5dQVgZHDEDEiCsANJEHYgCcIOJEHYgSS4lDRwmWHIZiA5wg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0k0ht32zbZ/Yfuw7ddsf7mavsz2s7aPVvdL228XQK8aR4SxvULSioh42fYSSQckbZH0JUknI+Lbth+UtDQivtqwLEaEAVrW84gwETEVES9Xjz+UdFjSSkmbJe2uXrZbM38AAIyosUt5se01kj4t6VeSlkfElDTzB8H2jTXzjEsa77NPAH2a98COtj8laZ+kb0XEU7bfi4jrZtXfjYjifjub8UD7+hrY0fZCSU9K+mFEPFVNPlHtz1/Yr58eRKMA2jGfo/GW9KikwxHx3VmlvZK2VY+3SXpm8O0BGJT5HI2/S9IvJR2UdL6a/DXN7Lf/WNJqSb+X9IWIONmwLDbjgZbVbcbPe599EAg70L6+9tkBfPIRdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMR8xme/2fYvbB+2/ZrtL1fTd9r+o+1Xqtum9tsF0Kv5jM++QtKKiHjZ9hJJByRtkfQvkk5FxH/N+80YshloXd2QzWPzmHFK0lT1+EPbhyWtHGx7ANp2SfvsttdI+rSkX1WTdth+1fZjtpfWzDNue8L2RH+tAuhH42b8X15of0rSPknfioinbC+X9I6kkPRNzWzq/2vDMtiMB1pWtxk/r7DbXijpp5J+FhHfnaO+RtJPI+LvG5ZD2IGW1YV9PkfjLelRSYdnB706cHfB5yUd6rdJAO2Zz9H4uyT9UtJBSeeryV+TtFXSBs1sxh+TtL06mFdaFp/sQMv62owfFMIOtK/nzXgAlwfCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo0XnBywdyT9btbzG6ppo2hUexvVviR669Uge/vbusJQf8/+sTe3JyJiY2cNFIxqb6Pal0RvvRpWb2zGA0kQdiCJrsO+q+P3LxnV3ka1L4neejWU3jrdZwcwPF1/sgMYEsIOJNFJ2G3fZ/uI7TdsP9hFD3VsH7N9sBqGutPx6aox9KZtH5o1bZntZ20fre7nHGOvo95GYhjvwjDjna67roc/H/o+u+0Fkn4j6bOSJiXtl7Q1In491EZq2D4maWNEdP4FDNv/KOmUpP+5MLSW7f+UdDIivl39oVwaEV8dkd526hKH8W6pt7phxr+kDtfdIIc/70UXn+y3SXojIn4bEWck7ZG0uYM+Rl5EvCjp5EWTN0vaXT3erZn/LENX09tIiIipiHi5evyhpAvDjHe67gp9DUUXYV8p6Q+znk9qtMZ7D0k/t33A9njXzcxh+YVhtqr7Gzvu52KNw3gP00XDjI/Muutl+PN+dRH2uYamGaXzf/8QEbdK+mdJ/15trmJ+vidpnWbGAJyS9J0um6mGGX9S0lci4oMue5ltjr6Gst66CPukpJtnPV8l6XgHfcwpIo5X99OSntbMbscoOXFhBN3qfrrjfv4iIk5ExLmIOC/p++pw3VXDjD8p6YcR8VQ1ufN1N1dfw1pvXYR9v6T1ttfaXiTpi5L2dtDHx9heXB04ke3Fkj6n0RuKeq+kbdXjbZKe6bCXvzIqw3jXDTOujtdd58OfR8TQb5I2aeaI/JuSvt5FDzV9/Z2k/69ur3Xdm6QnNLNZ9yfNbBH9m6TrJT0v6Wh1v2yEentcM0N7v6qZYK3oqLe7NLNr+KqkV6rbpq7XXaGvoaw3vi4LJME36IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgiT8D2jwwuHBzLP4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [2, 4, 6, 8, 10]:\n",
    "    plt.imshow(array[i], cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(fas_train.shape)\n",
    "print(fas_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6000\n",
       "1    6000\n",
       "2    6000\n",
       "3    6000\n",
       "4    6000\n",
       "5    6000\n",
       "6    6000\n",
       "7    6000\n",
       "8    6000\n",
       "9    6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fas_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 T-shirt/top  \n",
    "1 Trouser  \n",
    "2 Pullover  \n",
    "3 Dress  \n",
    "4 Coat  \n",
    "5 Sandal  \n",
    "6 Shirt  \n",
    "7 Sneaker  \n",
    "8 Bag  \n",
    "9 Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "\n",
    "train데이터는 클래스별로 6000개씩 데이터가 있는데 60000개의 데이터로 돌리기에는  \n",
    "시간이 너무 많이 소요(아래에서 실험)  \n",
    "\n",
    "=> 프로젝트임을 고려하여 많은 시간과 정확도보다는 많은 테스트, 성능 향상 등에 초점  \n",
    "\n",
    "=> 각 클래스별로 랜덤하게 1000개씩을 뽑아 10000개의 데이터로 활용하고자 함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비어있는 DataFrame 생성\n",
    "fas_train_random = pd.DataFrame()\n",
    "\n",
    "# 각 클래스에서 1000개를 랜덤하게 뽑아서 fas_train_random에 저장\n",
    "for i in range(10) :\n",
    "    fas_ = fas_train[fas_train['label'] == i].sample(n=1000)\n",
    "    fas_train_random = fas_train_random.append(fas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fas_train_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27629</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>119</td>\n",
       "      <td>131</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>127</td>\n",
       "      <td>68</td>\n",
       "      <td>181</td>\n",
       "      <td>215</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>108</td>\n",
       "      <td>98</td>\n",
       "      <td>113</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>139</td>\n",
       "      <td>126</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40932</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>129</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38714</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>93</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38899</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>96</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13547</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12028</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21053</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>107</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>163</td>\n",
       "      <td>179</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59769</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>158</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40041</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53458</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17691</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>141</td>\n",
       "      <td>174</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "27629      0       0       0       0       0       0       0       0       0   \n",
       "57308      0       0       0       0       0       0       0       0       0   \n",
       "49291      0       0       0       0       0       0       0       0       0   \n",
       "40433      0       0       0       0       7     133     108      98     113   \n",
       "40932      0       0       0       0       0       0       0       1       0   \n",
       "38714      0       0       0       0       0       0       0       0       0   \n",
       "38899      0       0       0       0       0       0       1       0       0   \n",
       "4042       0       0       0       0       0       0       0       0       0   \n",
       "13547      0       0       0       0       0       0       2       0       0   \n",
       "12028      0       0       0       0       0       0       0       1       3   \n",
       "21053      0       0       0       0       0       0       0       0       0   \n",
       "7563       0       0       0       0       0       0       0       0       0   \n",
       "42129      0       0       0       0       0       0       0       0       0   \n",
       "7171       0       0       0       0       0       0       0       0       0   \n",
       "27652      0       0       0       2       0       0       0       0       0   \n",
       "59769      0       0       0       0       0       0       0       0       0   \n",
       "40041      0       0       0       0       0       0       0       1       2   \n",
       "53458      0       0       0       0       0       1       1       0       0   \n",
       "17691      0       0       0       0       0       0       0       0       0   \n",
       "44025      0       0       0       0       0       0       0       3       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "27629       0  ...         0         0         0         0         0   \n",
       "57308       0  ...       123       119       131        38         0   \n",
       "49291       0  ...        62       127        68       181       215   \n",
       "40433     143  ...         0         0         0         4         0   \n",
       "40932       3  ...       144       129        73         0         0   \n",
       "38714       0  ...       111        93        87        15         0   \n",
       "38899       0  ...        93        96        83         0         0   \n",
       "4042        0  ...         0         0         0         0         0   \n",
       "13547       0  ...        19         0         0         0         1   \n",
       "12028       3  ...         0         0         0         1         3   \n",
       "21053       0  ...        99       107        28         0         1   \n",
       "7563        0  ...       172       165       156        36         0   \n",
       "42129       0  ...        81        65         6         0         0   \n",
       "7171        0  ...         0         0         0         0         0   \n",
       "27652      32  ...       168       163       179        19         0   \n",
       "59769       0  ...        96       100       158        17         0   \n",
       "40041       0  ...        69        12         0         0         1   \n",
       "53458       0  ...        41         9         0         0         0   \n",
       "17691       0  ...       146       141       174        26         0   \n",
       "44025       0  ...       111        49         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "27629         0         0         2         0         0  \n",
       "57308         0         0         0         0         0  \n",
       "49291       122         0         0         0         0  \n",
       "40433        46       139       126        59         0  \n",
       "40932         2         0         0         0         0  \n",
       "38714         0         0         0         0         0  \n",
       "38899         0         0         0         0         0  \n",
       "4042          0         0         0         0         0  \n",
       "13547         0         0         0         0         0  \n",
       "12028         0         0         0         0         0  \n",
       "21053         0         0         0         0         0  \n",
       "7563          5         0         0         0         0  \n",
       "42129         1         0         0         0         0  \n",
       "7171          0         0         0         0         0  \n",
       "27652         2         0         0         0         0  \n",
       "59769         4         0         0         0         0  \n",
       "40041         0         0         0         0         0  \n",
       "53458         0         0         0         0         0  \n",
       "17691         4         0         0         0         0  \n",
       "44025         0         0         0         0         0  \n",
       "\n",
       "[20 rows x 785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fas_train_random.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 클래스가 0부터 9까지 정렬되어있는 상태이므로 이를 적절하게 섞어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fas_train_new = fas_train_random.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19828</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>194</td>\n",
       "      <td>170</td>\n",
       "      <td>108</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42162</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51591</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26579</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19087</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52806</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14354</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57014</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41202</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>110</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33574</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52338</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>227</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28163</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45102</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43098</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22515</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58634</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "19828      1       0       0       0       0       0       0       1       0   \n",
       "42162      0       0       0       0       0       0       0       0       0   \n",
       "51591      2       0       0       0       0       0       0       0       0   \n",
       "26579      6       0       0       0       0       0       0       0       0   \n",
       "19087      6       0       0       0       0       0       0       0       0   \n",
       "52806      3       0       0       0       0       0       0       0       0   \n",
       "14354      3       0       0       0       0       0       0       0       0   \n",
       "5562       8       0       0       0       0       0       0       0       0   \n",
       "57014      7       0       0       0       0       0       0       0       0   \n",
       "41202      6       0       0       0       0       0       0       0       0   \n",
       "33574      4       0       0       0       0       0       0       0       0   \n",
       "52338      2       0       0       0       0       0       0       0       0   \n",
       "8130       1       0       0       0       0       0       0       0       0   \n",
       "38348      0       0       0       0       2       0       2       0       0   \n",
       "28163      9       0       0       0       0       0       0       0       0   \n",
       "45102      1       0       0       0       0       0       0       0       0   \n",
       "15111      8       0       0       0       0       0       0       0       0   \n",
       "43098      1       0       0       0       0       0       0       0       0   \n",
       "22515      5       0       0       0       0       0       0       0       0   \n",
       "58634      5       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "19828       0  ...       194       170       108        69         6   \n",
       "42162       0  ...       154       156       160         0         0   \n",
       "51591       0  ...         2         0         0         0         1   \n",
       "26579       1  ...         0         0         0         0         0   \n",
       "19087       4  ...         0         0         0       151        69   \n",
       "52806       0  ...        73         0         0         0         0   \n",
       "14354       1  ...       163        57         0         0         1   \n",
       "5562        0  ...         0         0         0         0         0   \n",
       "57014       0  ...         0         0         0         0         0   \n",
       "41202       0  ...         0         0         0         0       173   \n",
       "33574       0  ...         0         0         0         0         0   \n",
       "52338       1  ...         0         0       104       227        98   \n",
       "8130        0  ...       126         0         0         0         0   \n",
       "38348       0  ...        80        20         0         0         0   \n",
       "28163       0  ...         0         0         0         0         0   \n",
       "45102       0  ...       144        29         0         0         0   \n",
       "15111       0  ...         0         0         0         0         0   \n",
       "43098       0  ...         0         0         0         0         0   \n",
       "22515       0  ...         0         0         0         0         0   \n",
       "58634       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "19828         0         0         0         0         0  \n",
       "42162         1         0         0         0         0  \n",
       "51591         0         0         0         0         0  \n",
       "26579         0         0         0         0         0  \n",
       "19087         3         0         0         0         0  \n",
       "52806         0         0         0         0         0  \n",
       "14354         0         0         0         0         0  \n",
       "5562          0         0         0         0         0  \n",
       "57014         0         0         0         0         0  \n",
       "41202       110        61         0         0         0  \n",
       "33574         0         0         0         0         0  \n",
       "52338         0         0         0         0         0  \n",
       "8130          0         0         0         0         0  \n",
       "38348         0         3         0         0         0  \n",
       "28163         0         0         0         0         0  \n",
       "45102         0         0         0         0         0  \n",
       "15111         0         0         0         0         0  \n",
       "43098         0         0         0         0         0  \n",
       "22515         0         0         0         0         0  \n",
       "58634         0         0         0         0         0  \n",
       "\n",
       "[20 rows x 785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fas_train_new.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 원본 데이터(60000) KNN 검증\n",
    "\n",
    "시간 측정을 위해 원본 데이터(60000행)로 knn과 cross_Validation을 사용한 결과  \n",
    "\n",
    "약 30분 이상의 시간이 소요됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(fas_train.drop(['label'], axis = 1), fas_train['label'], test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(clf, X = X_val, y = y_val, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8275     0.81791667 0.81416667 0.82458333 0.81583333]\n"
     ]
    }
   ],
   "source": [
    "print(cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fas_train_new 데이터의 80%를 훈련 데이터로, 20%를 검증 데이터로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fas_train_new.drop(['label'], axis = 1)\n",
    "y = fas_train_new['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터에 대해서 전체 데이터를 사용했을 때보다 조금 떨어진 성능을 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN을 통한 분류(검증 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79   0.7575 0.775  0.77   0.8025]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(knn, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[167   0   7   4   1   0  24   0   1   0]\n",
      " [  2 201   2   1   0   0   2   0   0   1]\n",
      " [  9   0 145   2  28   0  14   0   0   0]\n",
      " [ 11   0   3 151   8   0   6   0   1   0]\n",
      " [  1   0  28   7 150   0  27   0   0   0]\n",
      " [  0   0   0   0   0 158   0  39   0  14]\n",
      " [ 44   0  33   4  12   0 111   0   4   0]\n",
      " [  0   0   0   0   0   2   0 168   0  17]\n",
      " [  4   1   4   1   1   0   2   1 182   0]\n",
      " [  0   0   1   0   0   0   0   4   0 189]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76       204\n",
      "           1       1.00      0.96      0.98       209\n",
      "           2       0.65      0.73      0.69       198\n",
      "           3       0.89      0.84      0.86       180\n",
      "           4       0.75      0.70      0.73       213\n",
      "           5       0.99      0.75      0.85       211\n",
      "           6       0.60      0.53      0.56       208\n",
      "           7       0.79      0.90      0.84       187\n",
      "           8       0.97      0.93      0.95       196\n",
      "           9       0.86      0.97      0.91       194\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.82      0.81      0.81      2000\n",
      "weighted avg       0.82      0.81      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN을 통한 분류(테스트 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트 준비\n",
    "X_test = fas_test.drop(['label'], axis = 1)\n",
    "y_test = fas_test['label']\n",
    "\n",
    "y_test_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.814  0.8215 0.8165 0.804  0.833 ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(knn, X = X_test, y = y_test, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "[[821   1  30  17   4   0 114   1  12   0]\n",
      " [ 12 956   6  16   2   0   8   0   0   0]\n",
      " [ 28   2 770  12 106   0  78   1   3   0]\n",
      " [ 64  17  12 861  30   0  16   0   0   0]\n",
      " [  7   0 164  50 697   0  81   0   1   0]\n",
      " [  5   0   2   1   0 730  10 153   5  94]\n",
      " [222   1 136  23  67   0 544   0   7   0]\n",
      " [  0   0   0   0   0   9   0 907   0  84]\n",
      " [  9   2  24   4   9   0  17  11 921   3]\n",
      " [  0   0   1   0   0   9   0  39   0 951]]\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76      1000\n",
      "           1       0.98      0.96      0.97      1000\n",
      "           2       0.67      0.77      0.72      1000\n",
      "           3       0.88      0.86      0.87      1000\n",
      "           4       0.76      0.70      0.73      1000\n",
      "           5       0.98      0.73      0.84      1000\n",
      "           6       0.63      0.54      0.58      1000\n",
      "           7       0.82      0.91      0.86      1000\n",
      "           8       0.97      0.92      0.95      1000\n",
      "           9       0.84      0.95      0.89      1000\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN 결과 분석\n",
    "\n",
    "1. 검증 데이터에 비해서 테스트 데이터가 조금 더 정확한 결과를 보임  \n",
    "2. 4번(코트)과 6번(셔츠)가 비교적 낮은 정확도를 보임  \n",
    "3. 비교적 안정적인 결과를 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest를 통한 분류(검증 데이터)\n",
    "\n",
    "1. n_estimators = 10, max_depth = 5  \n",
    "- 시간을 계산하기 위해서 작은 값으로 설정(1초 이내)  \n",
    "- 정확도가 매우 낮음(6번의 경우 f1점수가 : 0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.765  0.7525 0.695  0.7325 0.775 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 10, max_depth = 5, random_state = 0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(rf, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[166   1  11  20   3   1   1   0   1   0]\n",
      " [  0 181   0  28   0   0   0   0   0   0]\n",
      " [  3   0 133   2  55   0   3   0   2   0]\n",
      " [ 10   1   6 158   4   0   1   0   0   0]\n",
      " [  2   0  28  24 155   0   1   0   3   0]\n",
      " [  0   0   0   0   0 181   0  20   2   8]\n",
      " [ 52   0  52  16  62   1  14   0  11   0]\n",
      " [  0   0   0   0   0   6   0 155   0  26]\n",
      " [  0   0   9   5   4   1   0   0 177   0]\n",
      " [  0   0   0   1   0   4   0  12   0 177]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76       204\n",
      "           1       0.99      0.87      0.92       209\n",
      "           2       0.56      0.67      0.61       198\n",
      "           3       0.62      0.88      0.73       180\n",
      "           4       0.55      0.73      0.62       213\n",
      "           5       0.93      0.86      0.89       211\n",
      "           6       0.70      0.07      0.12       208\n",
      "           7       0.83      0.83      0.83       187\n",
      "           8       0.90      0.90      0.90       196\n",
      "           9       0.84      0.91      0.87       194\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.76      0.75      0.73      2000\n",
      "weighted avg       0.76      0.75      0.72      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. n_estimators = 100, max_depth = 20  \n",
    "- 시간 : 약 40초 내외  \n",
    "- 성능은 향상(6번에 대한 정확도가 비약적으로 상승, 다른 부분들도 준수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8225 0.805  0.81   0.8175 0.795 ]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 20, random_state = 0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(rf, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[170   0   5   7   1   0  21   0   0   0]\n",
      " [  1 203   1   3   0   0   1   0   0   0]\n",
      " [  2   0 151   3  31   0  10   0   1   0]\n",
      " [  5   0   1 161   8   0   4   0   1   0]\n",
      " [  1   0  17   8 173   0  12   0   2   0]\n",
      " [  0   0   0   0   0 195   0  11   2   3]\n",
      " [ 34   0  23   6  23   0 115   0   7   0]\n",
      " [  0   0   0   0   0   6   0 165   0  16]\n",
      " [  1   0   2   1   2   1   2   0 187   0]\n",
      " [  0   0   0   0   0   4   0   8   0 182]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       204\n",
      "           1       1.00      0.97      0.99       209\n",
      "           2       0.76      0.76      0.76       198\n",
      "           3       0.85      0.89      0.87       180\n",
      "           4       0.73      0.81      0.77       213\n",
      "           5       0.95      0.92      0.94       211\n",
      "           6       0.70      0.55      0.62       208\n",
      "           7       0.90      0.88      0.89       187\n",
      "           8       0.94      0.95      0.94       196\n",
      "           9       0.91      0.94      0.92       194\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. GridSearch를 통해서 최적의 파라미터 추출\n",
    "- 시간 : 2시간 이상\n",
    "- 성능이 2번에 비해서 오히려 안좋음 => 조건을 많이 주는 것이 오히려 안좋을 수 있다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth':[30, 50, 70],\n",
    "          'min_samples_leaf':[10, 15, 20],\n",
    "          'min_samples_split':[8, 16, 20],\n",
    "          'n_estimators':[100, 200, 400, 600]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'max_depth': [30, 50, 70],\n",
       "                         'min_samples_leaf': [10, 15, 20],\n",
       "                         'min_samples_split': [8, 16, 20],\n",
       "                         'n_estimators': [100, 200, 400, 600]})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "grid_cv = GridSearchCV(rf, params, cv=2)\n",
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 600}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8225 0.7875 0.785  0.81   0.79  ]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=600, max_depth=30, min_samples_leaf=10, min_samples_split=8, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(rf, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[165   1   4   9   0   0  24   0   1   0]\n",
      " [  1 201   3   3   0   0   1   0   0   0]\n",
      " [  4   0 146   1  39   1   5   0   2   0]\n",
      " [  5   1   1 160   7   0   6   0   0   0]\n",
      " [  1   0  14  10 173   0  14   0   1   0]\n",
      " [  0   0   0   0   0 193   0  13   1   4]\n",
      " [ 37   0  27   8  21   0 108   0   7   0]\n",
      " [  0   0   0   0   0   4   0 163   0  20]\n",
      " [  0   0   2   3   2   1   2   0 186   0]\n",
      " [  0   0   0   0   0   3   0   6   0 185]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       204\n",
      "           1       0.99      0.96      0.98       209\n",
      "           2       0.74      0.74      0.74       198\n",
      "           3       0.82      0.89      0.86       180\n",
      "           4       0.71      0.81      0.76       213\n",
      "           5       0.96      0.91      0.93       211\n",
      "           6       0.68      0.52      0.59       208\n",
      "           7       0.90      0.87      0.88       187\n",
      "           8       0.94      0.95      0.94       196\n",
      "           9       0.89      0.95      0.92       194\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. n_estimators = 500, max_depth = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8325 0.8025 0.8025 0.8225 0.7975]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, max_depth=20, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(rf, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[169   1   5   7   1   0  20   0   1   0]\n",
      " [  1 203   1   3   0   0   1   0   0   0]\n",
      " [  2   0 151   3  33   0   7   0   2   0]\n",
      " [  5   0   0 162   6   0   7   0   0   0]\n",
      " [  1   0  16   9 173   0  13   0   1   0]\n",
      " [  0   0   0   0   0 196   0  10   2   3]\n",
      " [ 34   0  25   8  20   0 114   0   7   0]\n",
      " [  0   0   0   0   0   3   0 167   0  17]\n",
      " [  1   0   2   1   2   0   1   0 189   0]\n",
      " [  0   0   0   0   0   4   0   6   0 184]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       204\n",
      "           1       1.00      0.97      0.98       209\n",
      "           2       0.76      0.76      0.76       198\n",
      "           3       0.84      0.90      0.87       180\n",
      "           4       0.74      0.81      0.77       213\n",
      "           5       0.97      0.93      0.95       211\n",
      "           6       0.70      0.55      0.61       208\n",
      "           7       0.91      0.89      0.90       187\n",
      "           8       0.94      0.96      0.95       196\n",
      "           9       0.90      0.95      0.92       194\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.86      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest를 통한 분류(테스트 데이터)\n",
    "\n",
    "테스트용 데이터 검증 모델로 n_estimators = 500, max_depth = 20 옵션을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.859  0.863  0.8615 0.8535 0.8605]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(rf, X = X_test, y = y_test, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "[[807   1  18  60   2   2  95   0  15   0]\n",
      " [  2 964   6  21   1   1   5   0   0   0]\n",
      " [  8   3 777   9 135   1  54   0  13   0]\n",
      " [ 22  10   6 920  22   0  19   0   1   0]\n",
      " [  1   1  69  41 848   0  36   0   4   0]\n",
      " [  0   0   0   0   0 923   0  50   5  22]\n",
      " [177   4 118  34  90   0 555   0  22   0]\n",
      " [  0   0   0   0   0  31   0 902   1  66]\n",
      " [  1   1   9   2   4   3   9   4 966   1]\n",
      " [  0   0   1   0   0  12   0  48   3 936]]\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1000\n",
      "           1       0.98      0.96      0.97      1000\n",
      "           2       0.77      0.78      0.78      1000\n",
      "           3       0.85      0.92      0.88      1000\n",
      "           4       0.77      0.85      0.81      1000\n",
      "           5       0.95      0.92      0.94      1000\n",
      "           6       0.72      0.56      0.63      1000\n",
      "           7       0.90      0.90      0.90      1000\n",
      "           8       0.94      0.97      0.95      1000\n",
      "           9       0.91      0.94      0.92      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest 결과 분석\n",
    "\n",
    "1. 검증 데이터에 비해서 테스트 데이터가 조금 더 정확한 결과를 보임  \n",
    "2. KNN에 비하면 전체적으로 높은 정확도  \n",
    "3. 6번은 정확도가 아직 많이 부족하지만 다른 클래스들은 비교적 잘 분류함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost을 통한 분류(검증 데이터)\n",
    "\n",
    "1. default  \n",
    "- 전체적인 정확도는 랜덤 포레스트와 비슷함\n",
    "- 6번에 대한 정확도가 많이 올라감 => XGBoost을 통해서 전체적인 정확도를 보장할 수 있다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.865  0.795  0.805  0.815  0.8075]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(xgb, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173   0   4   9   1   0  17   0   0   0]\n",
      " [  1 204   0   2   0   0   2   0   0   0]\n",
      " [  7   0 159   1  21   0   9   0   1   0]\n",
      " [  5   0   3 161   8   0   3   0   0   0]\n",
      " [  0   0  15   6 180   0  12   0   0   0]\n",
      " [  0   0   0   0   0 197   0  11   0   3]\n",
      " [ 24   0  26   6  14   0 133   0   5   0]\n",
      " [  0   0   0   0   0   1   0 175   0  11]\n",
      " [  1   0   1   1   4   0   4   0 185   0]\n",
      " [  0   0   0   0   0   2   0   5   0 187]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       204\n",
      "           1       1.00      0.98      0.99       209\n",
      "           2       0.76      0.80      0.78       198\n",
      "           3       0.87      0.89      0.88       180\n",
      "           4       0.79      0.85      0.82       213\n",
      "           5       0.98      0.93      0.96       211\n",
      "           6       0.74      0.64      0.69       208\n",
      "           7       0.92      0.94      0.93       187\n",
      "           8       0.97      0.94      0.96       196\n",
      "           9       0.93      0.96      0.95       194\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.88      0.88      0.88      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 초기값 설정 (참고 : https://www.kaggle.com/lifesailor/xgboost)\n",
    "- 평균적으로 0.88의 정확도를 보임\n",
    "- 좋은 모델이지만 시간이 많이 소요(cross_validation 과정에서 한 번당 약 20분의 시간이 필요)\n",
    "- n_estimators를 조금 줄이고, 다른 파라미터를 조절하고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:25:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:25:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:28:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:28:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:31:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:31:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:33:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:33:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.8575 0.8175 0.815  0.8225 0.835 ]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    )\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(xgb, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173   1   3   9   0   0  18   0   0   0]\n",
      " [  1 205   0   1   0   0   2   0   0   0]\n",
      " [  5   0 158   2  23   0   9   0   1   0]\n",
      " [  6   1   1 160   7   0   5   0   0   0]\n",
      " [  0   0  19   7 173   0  14   0   0   0]\n",
      " [  0   0   0   0   0 195   0  12   1   3]\n",
      " [ 20   0  22   7  16   0 139   0   4   0]\n",
      " [  0   0   0   0   0   1   0 175   0  11]\n",
      " [  1   0   2   0   3   0   3   1 186   0]\n",
      " [  0   0   0   0   0   2   0   5   0 187]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       204\n",
      "           1       0.99      0.98      0.99       209\n",
      "           2       0.77      0.80      0.78       198\n",
      "           3       0.86      0.89      0.87       180\n",
      "           4       0.78      0.81      0.80       213\n",
      "           5       0.98      0.92      0.95       211\n",
      "           6       0.73      0.67      0.70       208\n",
      "           7       0.91      0.94      0.92       187\n",
      "           8       0.97      0.95      0.96       196\n",
      "           9       0.93      0.96      0.95       194\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.88      0.88      0.88      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 파라미터 튜닝\n",
    "- 2번보다 정확도가 떨어짐 다른 방향을 고려해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:50:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:58:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:00:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:02:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.8575 0.795  0.8175 0.8075 0.8075]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=400,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    )\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(xgb, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[172   1   4   8   0   0  18   0   1   0]\n",
      " [  2 200   2   4   0   0   1   0   0   0]\n",
      " [  4   0 149   2  32   1   9   0   1   0]\n",
      " [  6   1   1 159   8   0   5   0   0   0]\n",
      " [  0   0  18   9 169   0  17   0   0   0]\n",
      " [  0   0   0   0   0 192   0  15   1   3]\n",
      " [ 28   0  24   7  22   1 121   0   5   0]\n",
      " [  0   0   0   0   0   1   0 171   0  15]\n",
      " [  1   0   2   3   5   0   4   0 181   0]\n",
      " [  0   0   0   0   0   1   0   3   0 190]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82       204\n",
      "           1       0.99      0.96      0.97       209\n",
      "           2       0.74      0.75      0.75       198\n",
      "           3       0.83      0.88      0.85       180\n",
      "           4       0.72      0.79      0.75       213\n",
      "           5       0.98      0.91      0.94       211\n",
      "           6       0.69      0.58      0.63       208\n",
      "           7       0.90      0.91      0.91       187\n",
      "           8       0.96      0.92      0.94       196\n",
      "           9       0.91      0.98      0.95       194\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 파라미터 튜닝\n",
    "- n_estimators를 유지하고, 다른 매개변수를 조절하고자 함\n",
    "- 초기값 모델(1번)에는 조금 못 미치는 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:12:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:24:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:27:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.8625 0.8025 0.8    0.82   0.8225]\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=1000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    )\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_val)\n",
    "\n",
    "cvs = cross_val_score(xgb, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[167   1   3  10   0   0  22   0   1   0]\n",
      " [  2 202   1   2   1   0   1   0   0   0]\n",
      " [  3   0 150   1  30   1  12   0   1   0]\n",
      " [  6   1   1 158   9   0   5   0   0   0]\n",
      " [  0   0  20   7 168   0  18   0   0   0]\n",
      " [  0   0   0   0   0 195   0  12   1   3]\n",
      " [ 32   0  22   7  20   0 123   0   4   0]\n",
      " [  0   0   0   0   0   0   0 175   0  12]\n",
      " [  0   0   1   2   4   0   4   0 185   0]\n",
      " [  0   0   0   0   0   1   0   4   0 189]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       204\n",
      "           1       0.99      0.97      0.98       209\n",
      "           2       0.76      0.76      0.76       198\n",
      "           3       0.84      0.88      0.86       180\n",
      "           4       0.72      0.79      0.76       213\n",
      "           5       0.99      0.92      0.96       211\n",
      "           6       0.66      0.59      0.63       208\n",
      "           7       0.92      0.94      0.93       187\n",
      "           8       0.96      0.94      0.95       196\n",
      "           9       0.93      0.97      0.95       194\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. GridSearch를 통해서 최적의 파라미터 추출\n",
    "- 시간 : 3시간 30분\n",
    "- 초기값 모델에서 max_depth, min_child_weight, gamma만 변경하여 최적의 파라미터를 찾고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:33:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:43:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:47:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:56:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:04:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:15:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:20:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:24:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:28:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:34:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:41:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:46:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:14:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:19:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:33:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:45:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:21:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:28:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:32:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8, gamma=0.1,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_delta_step=None,\n",
       "                                     max_depth=5, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=1000, n_jobs=None, nthread=-1,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=0.8,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'gamma': [0.1, 0.2], 'max_depth': [3, 4, 5],\n",
       "                         'min_child_weight': [1, 3, 5]})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth':[3,4,5],\n",
    "          'min_child_weight':[1,3,5],\n",
    "          'gamma':[0.1,0.2]\n",
    "         }\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    )\n",
    "\n",
    "grid_cv = GridSearchCV(xgb, params, cv=2)\n",
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.1, 'max_depth': 4, 'min_child_weight': 1}\n",
      "0.8612500000000001\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost를 통한 분류(테스트 데이터)\n",
    "\n",
    "테스트용 데이터 검증 모델로 GridSearch의 결과로 나온 옵션을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    )\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:33:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.8575 0.8025 0.805  0.815  0.825 ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(xgb, X = X_test, y = y_test, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "[[829   0  16  43   1   1  93   2  15   0]\n",
      " [  3 973   5  13   0   2   4   0   0   0]\n",
      " [ 13   2 821  12  77   0  67   0   8   0]\n",
      " [ 20   8   9 918  22   0  23   0   0   0]\n",
      " [  0   0  64  33 845   1  54   0   3   0]\n",
      " [  0   0   0   1   0 934   0  39   4  22]\n",
      " [141   5  92  27  65   1 658   0  11   0]\n",
      " [  0   0   0   0   0  15   0 929   1  55]\n",
      " [  1   1   7   3   3   4  12   2 965   2]\n",
      " [  0   0   0   0   0   5   1  47   4 943]]\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1000\n",
      "           1       0.98      0.97      0.98      1000\n",
      "           2       0.81      0.82      0.82      1000\n",
      "           3       0.87      0.92      0.90      1000\n",
      "           4       0.83      0.84      0.84      1000\n",
      "           5       0.97      0.93      0.95      1000\n",
      "           6       0.72      0.66      0.69      1000\n",
      "           7       0.91      0.93      0.92      1000\n",
      "           8       0.95      0.96      0.96      1000\n",
      "           9       0.92      0.94      0.93      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost 결과 분석\n",
    "\n",
    "1. 검증 데이터에 비해서 테스트 데이터가 조금 더 정확한 결과를 보임  \n",
    "2. 이전의 분류기에 비하면 높은 정확도\n",
    "3. 2번(초기값)과 전체적인 정확도는 비슷하지만, 2번이 특정 값들을 더 잘 분류했다면 최종 결과는 전체적으로 골고루 잘 분류한듯 함\n",
    "4. 6번에 대한 정확도는 0.7 내외가 한계라고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP를 통한 분류(검증 데이터)\n",
    "\n",
    "1. 초기값 설정  \n",
    "- 데이터의 크기를 고려하여 solver='adam'을 제공하였고, 데이터가 비교적 단순하여 레이어의 사이즈를 2개의 은닉층에 10개의 노드를 사용함.\n",
    "- 모두 3으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10),\n",
    "                    alpha=0.0001,\n",
    "                    solver='adam',\n",
    "                    max_iter=100,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1075 0.105  0.1025 0.105  0.105 ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[  0   0   0 204   0   0   0   0   0   0]\n",
      " [  0   0   0 209   0   0   0   0   0   0]\n",
      " [  0   0   0 198   0   0   0   0   0   0]\n",
      " [  0   0   0 180   0   0   0   0   0   0]\n",
      " [  0   0   0 213   0   0   0   0   0   0]\n",
      " [  0   0   0 211   0   0   0   0   0   0]\n",
      " [  0   0   0 208   0   0   0   0   0   0]\n",
      " [  0   0   0 187   0   0   0   0   0   0]\n",
      " [  0   0   0 196   0   0   0   0   0   0]\n",
      " [  0   0   0 194   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       204\n",
      "           1       0.00      0.00      0.00       209\n",
      "           2       0.00      0.00      0.00       198\n",
      "           3       0.09      1.00      0.17       180\n",
      "           4       0.00      0.00      0.00       213\n",
      "           5       0.00      0.00      0.00       211\n",
      "           6       0.00      0.00      0.00       208\n",
      "           7       0.00      0.00      0.00       187\n",
      "           8       0.00      0.00      0.00       196\n",
      "           9       0.00      0.00      0.00       194\n",
      "\n",
      "    accuracy                           0.09      2000\n",
      "   macro avg       0.01      0.10      0.02      2000\n",
      "weighted avg       0.01      0.09      0.01      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 조금 더 복잡한 모델\n",
    "- 이번엔 모두 8로 예측 => 아직은 너무 간단한 모델이라고 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100),\n",
    "                    alpha=0.001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=100,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.105 0.105 0.105 0.105 0.105]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[  0   0   0   0   0   0   0   0 204   0]\n",
      " [  0   0   0   0   0   0   0   0 209   0]\n",
      " [  0   0   0   0   0   0   0   0 198   0]\n",
      " [  0   0   0   0   0   0   0   0 180   0]\n",
      " [  0   0   0   0   0   0   0   0 213   0]\n",
      " [  0   0   0   0   0   0   0   0 211   0]\n",
      " [  0   0   0   0   0   0   0   0 208   0]\n",
      " [  0   0   0   0   0   0   0   0 187   0]\n",
      " [  0   0   0   0   0   0   0   0 196   0]\n",
      " [  0   0   0   0   0   0   0   0 194   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       204\n",
      "           1       0.00      0.00      0.00       209\n",
      "           2       0.00      0.00      0.00       198\n",
      "           3       0.00      0.00      0.00       180\n",
      "           4       0.00      0.00      0.00       213\n",
      "           5       0.00      0.00      0.00       211\n",
      "           6       0.00      0.00      0.00       208\n",
      "           7       0.00      0.00      0.00       187\n",
      "           8       0.10      1.00      0.18       196\n",
      "           9       0.00      0.00      0.00       194\n",
      "\n",
      "    accuracy                           0.10      2000\n",
      "   macro avg       0.01      0.10      0.02      2000\n",
      "weighted avg       0.01      0.10      0.02      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 파라미터 튜닝\n",
    "- 은닉층을 복잡하게 설계하니 다양한 클래스로 예측함을 확인 => 조금 더 복잡하게 하고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 100, 100, 100, 10),\n",
    "                    alpha=0.001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=100,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39   0.2575 0.2    0.1975 0.2125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[ 77   0  71  48   0   0   0   0   7   1]\n",
      " [  0 199   3   6   0   0   0   0   0   1]\n",
      " [ 50   1 119  10   0   0   2   0  16   0]\n",
      " [ 25  40  18  94   0   0   0   1   2   0]\n",
      " [ 90   2  76  38   0   0   1   0   6   0]\n",
      " [  0   0   0   0   0 101   0  58   8  44]\n",
      " [ 54   2 110  24   0   0   1   0  17   0]\n",
      " [  0   0   0   0   0  54   0 118  10   5]\n",
      " [  1   0   6   2   0   0   1   2 184   0]\n",
      " [  0   0   0   0   0  17   0   2   0 175]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.38      0.31       204\n",
      "           1       0.82      0.95      0.88       209\n",
      "           2       0.30      0.60      0.40       198\n",
      "           3       0.42      0.52      0.47       180\n",
      "           4       0.00      0.00      0.00       213\n",
      "           5       0.59      0.48      0.53       211\n",
      "           6       0.20      0.00      0.01       208\n",
      "           7       0.65      0.63      0.64       187\n",
      "           8       0.74      0.94      0.83       196\n",
      "           9       0.77      0.90      0.83       194\n",
      "\n",
      "    accuracy                           0.53      2000\n",
      "   macro avg       0.47      0.54      0.49      2000\n",
      "weighted avg       0.47      0.53      0.48      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 파라미터 튜닝\n",
    "- 더욱 복잡한 은닉층을 만듦\n",
    "- 결과는 아직 좋지 않지만 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 200, 200, 100, 100),\n",
    "                    alpha=0.001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.795  0.7475 0.78   0.79   0.77  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[162   0   5  10   0   0  27   0   0   0]\n",
      " [  1 204   1   3   0   0   0   0   0   0]\n",
      " [  7   1 143   1  22   0  22   0   2   0]\n",
      " [  9   2   1 153   9   0   4   0   1   1]\n",
      " [  3   0  25   5 160   0  20   0   0   0]\n",
      " [  0   0   0   0   0 184   0  14   4   9]\n",
      " [ 30   0  23   5  18   0 127   0   5   0]\n",
      " [  0   0   0   0   0   9   0 166   0  12]\n",
      " [  0   0   4   3   2   1   3   1 182   0]\n",
      " [  0   0   0   0   0   6   0   8   0 180]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78       204\n",
      "           1       0.99      0.98      0.98       209\n",
      "           2       0.71      0.72      0.71       198\n",
      "           3       0.85      0.85      0.85       180\n",
      "           4       0.76      0.75      0.75       213\n",
      "           5       0.92      0.87      0.90       211\n",
      "           6       0.63      0.61      0.62       208\n",
      "           7       0.88      0.89      0.88       187\n",
      "           8       0.94      0.93      0.93       196\n",
      "           9       0.89      0.93      0.91       194\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 파라미터 튜닝\n",
    "- cross_validation의 결과는 그렇게 좋지는 않지만 꽤나 안정적인 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 200, 200, 300, 200, 200, 100, 100),\n",
    "                    alpha=0.001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82   0.755  0.7925 0.76   0.7775]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[160   1   6  10   0   1  24   0   2   0]\n",
      " [  1 202   1   3   0   0   2   0   0   0]\n",
      " [  6   0 147   2  25   1  14   0   3   0]\n",
      " [  8   2   2 155   7   0   5   0   1   0]\n",
      " [  1   0  20   9 171   0  11   0   1   0]\n",
      " [  0   0   0   0   0 191   0  14   1   5]\n",
      " [ 22   1  17   7  20   1 134   0   6   0]\n",
      " [  0   0   0   0   0   4   0 170   0  13]\n",
      " [  2   1   3   1   2   1   4   1 180   1]\n",
      " [  0   0   0   0   0   1   0   8   0 185]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79       204\n",
      "           1       0.98      0.97      0.97       209\n",
      "           2       0.75      0.74      0.75       198\n",
      "           3       0.83      0.86      0.84       180\n",
      "           4       0.76      0.80      0.78       213\n",
      "           5       0.95      0.91      0.93       211\n",
      "           6       0.69      0.64      0.67       208\n",
      "           7       0.88      0.91      0.89       187\n",
      "           8       0.93      0.92      0.92       196\n",
      "           9       0.91      0.95      0.93       194\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 파라미터 튜닝\n",
    "- 은닉층의 수를 줄이고 노드 수를 증가시킴\n",
    "- 이전과 비슷한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200, 200, 200, 300, 200, 200, 200),\n",
    "                    alpha=0.0001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.815  0.79   0.805  0.77   0.7975]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[159   2   4   8   1   2  28   0   0   0]\n",
      " [  0 204   0   3   1   0   0   0   0   1]\n",
      " [  5   0 149   1  29   0  13   0   1   0]\n",
      " [  8   1   1 157   8   0   4   0   1   0]\n",
      " [  1   1  21   6 170   0  13   0   1   0]\n",
      " [  0   0   0   0   0 183   1  19   1   7]\n",
      " [ 26   0  16   5  18   0 140   0   3   0]\n",
      " [  0   0   0   0   0   6   0 173   0   8]\n",
      " [  1   0   3   3   3   2   5   0 179   0]\n",
      " [  0   0   0   0   0   1   0   8   0 185]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79       204\n",
      "           1       0.98      0.98      0.98       209\n",
      "           2       0.77      0.75      0.76       198\n",
      "           3       0.86      0.87      0.87       180\n",
      "           4       0.74      0.80      0.77       213\n",
      "           5       0.94      0.87      0.90       211\n",
      "           6       0.69      0.67      0.68       208\n",
      "           7       0.86      0.93      0.89       187\n",
      "           8       0.96      0.91      0.94       196\n",
      "           9       0.92      0.95      0.94       194\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 파라미터 튜닝\n",
    "- 단순히 은닉층 수를 늘리고 노드 수를 늘린다고 결과가 좋지는 않음\n",
    "- 적절한 조절이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(300, 300, 300, 300, 300, 300, 300, 300, 300),\n",
    "                    alpha=0.0001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82   0.7525 0.7975 0.785  0.85  ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[164   0   8  10   0   1  21   0   0   0]\n",
      " [  0 203   2   3   0   0   0   0   0   1]\n",
      " [  6   0 153   2  23   1  13   0   0   0]\n",
      " [  8   1   3 153  10   0   2   0   3   0]\n",
      " [  0   0  26   8 159   0  19   0   1   0]\n",
      " [  0   0   0   0   0 189   0  14   1   7]\n",
      " [ 31   0  16   7  20   0 128   0   6   0]\n",
      " [  0   0   0   0   0   8   0 169   0  10]\n",
      " [  1   0   4   1   1   1   3   0 185   0]\n",
      " [  0   0   0   0   0   3   0   8   0 183]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       204\n",
      "           1       1.00      0.97      0.98       209\n",
      "           2       0.72      0.77      0.75       198\n",
      "           3       0.83      0.85      0.84       180\n",
      "           4       0.75      0.75      0.75       213\n",
      "           5       0.93      0.90      0.91       211\n",
      "           6       0.69      0.62      0.65       208\n",
      "           7       0.88      0.90      0.89       187\n",
      "           8       0.94      0.94      0.94       196\n",
      "           9       0.91      0.94      0.93       194\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 파라미터 튜닝\n",
    "- 은닉층의 수가 감소 => 한 가지 클래스로 예측\n",
    "- 은닉층은 10개에 가깝도록\n",
    "- 이후에 알파 값을 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(500, 500, 500),\n",
    "                    alpha=0.01,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\extmath.py:152: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_base.py:66: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45   0.095  0.0925 0.1025 0.0925]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[  0   0   0   0   0   0   0 204   0   0]\n",
      " [  0   0   0   0   0   0   0 209   0   0]\n",
      " [  0   0   0   0   0   0   0 198   0   0]\n",
      " [  0   0   0   0   0   0   0 180   0   0]\n",
      " [  0   0   0   0   0   0   0 213   0   0]\n",
      " [  1   0   0   0   0   0   0 210   0   0]\n",
      " [  0   0   0   0   0   0   0 208   0   0]\n",
      " [  0   0   0   0   0   0   0 187   0   0]\n",
      " [  0   0   0   0   0   0   0 196   0   0]\n",
      " [  0   0   0   0   0   0   0 194   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       204\n",
      "           1       0.00      0.00      0.00       209\n",
      "           2       0.00      0.00      0.00       198\n",
      "           3       0.00      0.00      0.00       180\n",
      "           4       0.00      0.00      0.00       213\n",
      "           5       0.00      0.00      0.00       211\n",
      "           6       0.00      0.00      0.00       208\n",
      "           7       0.09      1.00      0.17       187\n",
      "           8       0.00      0.00      0.00       196\n",
      "           9       0.00      0.00      0.00       194\n",
      "\n",
      "    accuracy                           0.09      2000\n",
      "   macro avg       0.01      0.10      0.02      2000\n",
      "weighted avg       0.01      0.09      0.02      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 파라미터 튜닝\n",
    "- 은닉층의 수를 증가, node를 조절, alpha를 0.01로 변경\n",
    "- 이전보다 뛰어나지는 못한 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 200, 300, 400, 500, 400, 300, 200, 100),\n",
    "                    alpha=0.01,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8075 0.75   0.7525 0.7925 0.8   ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[162   1   7   9   1   0  24   0   0   0]\n",
      " [  3 202   1   2   0   0   1   0   0   0]\n",
      " [  7   0 152   1  26   0  12   0   0   0]\n",
      " [ 11   2   3 151   6   0   6   0   1   0]\n",
      " [  1   1  21   7 166   0  17   0   0   0]\n",
      " [  0   0   0   0   0 193   0  12   1   5]\n",
      " [ 31   0  23   5  27   0 119   0   3   0]\n",
      " [  0   0   0   0   0   6   0 171   0  10]\n",
      " [  2   0   3   1   1   2   4   0 182   1]\n",
      " [  0   0   0   0   0   1   0   6   0 187]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       204\n",
      "           1       0.98      0.97      0.97       209\n",
      "           2       0.72      0.77      0.75       198\n",
      "           3       0.86      0.84      0.85       180\n",
      "           4       0.73      0.78      0.75       213\n",
      "           5       0.96      0.91      0.93       211\n",
      "           6       0.65      0.57      0.61       208\n",
      "           7       0.90      0.91      0.91       187\n",
      "           8       0.97      0.93      0.95       196\n",
      "           9       0.92      0.96      0.94       194\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 파라미터 튜닝\n",
    "- 이제까지 가장 좋았던 파라미터(6.)을 가져와서 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200, 200, 200, 200, 200, 200, 200),\n",
    "                    alpha=0.001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8125 0.7475 0.7825 0.765  0.8   ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[158   1   6  11   1   1  26   0   0   0]\n",
      " [  1 203   1   2   0   0   2   0   0   0]\n",
      " [  6   0 156   1  26   0   9   0   0   0]\n",
      " [  7   3   1 153  11   0   4   0   1   0]\n",
      " [  2   1  25   4 164   0  16   0   1   0]\n",
      " [  0   0   1   0   0 192   0  10   1   7]\n",
      " [ 27   1  25   4  15   0 134   0   2   0]\n",
      " [  0   0   0   0   0   4   0 173   0  10]\n",
      " [  3   0   3   1   2   0   3   0 184   0]\n",
      " [  0   0   0   0   0   5   0  12   0 177]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       204\n",
      "           1       0.97      0.97      0.97       209\n",
      "           2       0.72      0.79      0.75       198\n",
      "           3       0.87      0.85      0.86       180\n",
      "           4       0.75      0.77      0.76       213\n",
      "           5       0.95      0.91      0.93       211\n",
      "           6       0.69      0.64      0.67       208\n",
      "           7       0.89      0.93      0.91       187\n",
      "           8       0.97      0.94      0.96       196\n",
      "           9       0.91      0.91      0.91       194\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. 파라미터 튜닝\n",
    "- 이전과 비슷한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(300, 300, 300, 300, 300, 300, 300),\n",
    "                    alpha=0.0001,\n",
    "                    solver='sgd',\n",
    "                    max_iter=200,\n",
    "                    random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.815  0.7875 0.7975 0.795  0.81  ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "[[165   0   3  15   0   1  19   0   1   0]\n",
      " [  0 203   2   2   1   0   1   0   0   0]\n",
      " [  7   1 152   2  23   0  11   0   2   0]\n",
      " [  6   2   3 154  10   1   4   0   0   0]\n",
      " [  2   1  25   6 164   0  13   0   2   0]\n",
      " [  0   0   0   0   0 185   0  14   3   9]\n",
      " [ 27   1  18   6  20   0 130   0   6   0]\n",
      " [  0   0   0   0   0   5   0 174   0   8]\n",
      " [  4   0   4   1   3   3   2   0 179   0]\n",
      " [  0   0   0   0   0   5   0   9   0 180]]\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80       204\n",
      "           1       0.98      0.97      0.97       209\n",
      "           2       0.73      0.77      0.75       198\n",
      "           3       0.83      0.86      0.84       180\n",
      "           4       0.74      0.77      0.76       213\n",
      "           5       0.93      0.88      0.90       211\n",
      "           6       0.72      0.62      0.67       208\n",
      "           7       0.88      0.93      0.91       187\n",
      "           8       0.93      0.91      0.92       196\n",
      "           9       0.91      0.93      0.92       194\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"검증 데이터 : \")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP를 통한 분류(테스트 데이터)\n",
    "\n",
    "11. 의 결과를 사용  \n",
    "- 해당 모델 선정 이유 : 다른 것들에 비해서 크게 좋지는 않지만 6번에 대한 예측이 좋고, 전체적으로 안정적이라고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8445 0.842  0.853  0.838  0.863 ]\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(mlp, X = X_test, y = y_test, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "[[796   6  23  42   5   3 111   1  13   0]\n",
      " [  6 964   3  21   1   0   4   0   0   1]\n",
      " [ 25   5 754  17 103   3  84   0   9   0]\n",
      " [ 28  17  15 868  42   0  24   0   6   0]\n",
      " [  2   3  84  37 792   1  73   0   8   0]\n",
      " [  4   0   0   2   0 889   1  60  12  32]\n",
      " [143   5  93  33 101   0 609   0  15   1]\n",
      " [  0   0   0   0   0  39   0 918   0  43]\n",
      " [  8   3   9   2   9   9  12  11 935   2]\n",
      " [  0   0   0   0   0  21   0  48   0 931]]\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79      1000\n",
      "           1       0.96      0.96      0.96      1000\n",
      "           2       0.77      0.75      0.76      1000\n",
      "           3       0.85      0.87      0.86      1000\n",
      "           4       0.75      0.79      0.77      1000\n",
      "           5       0.92      0.89      0.90      1000\n",
      "           6       0.66      0.61      0.64      1000\n",
      "           7       0.88      0.92      0.90      1000\n",
      "           8       0.94      0.94      0.94      1000\n",
      "           9       0.92      0.93      0.93      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.84      0.85      0.84     10000\n",
      "weighted avg       0.84      0.85      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"테스트 데이터 : \")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP 결과 분석\n",
    "\n",
    "1. 파라미터 튜닝에 크게 영향을 받음을 확인 => 은닉층의 수가 적을 때, 한 클래스로만 예측\n",
    "2. 정확도가 XGBoost에 비해서 크게 좋지 않음\n",
    "3. 파라미터 조정이 어려워서 정확도를 높이기 위해서 더 많은 시도가 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voting을 통한 분류(검증 데이터)\n",
    "\n",
    "1. hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:09:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=3)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=20,\n",
       "                                                     n_estimators=500,\n",
       "                                                     random_state=0)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=0.8, gamma=0.1,\n",
       "                                            gpu_id=-1, importance_type='gain',\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.1, max_delta_step=0,\n",
       "                                            max_depth=4, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=1000, n_jobs=8,\n",
       "                                            nthread=-1, num_parallel_tree=1,\n",
       "                                            objective='multi:softprob',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=None,\n",
       "                                            subsample=0.8, tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None))])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vot= VotingClassifier(estimators=[('knn',knn),\n",
    "                                         ('rf',rf),\n",
    "                                         ('xgb', xgb)],\n",
    "                             voting='hard')\n",
    "vot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(vot, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot= VotingClassifier(estimators=[('knn',knn),\n",
    "                                         ('rf',rf),\n",
    "                                         ('xgb', xgb)],\n",
    "                             voting='soft')\n",
    "vot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = cross_val_score(vot, X = X_val, y = y_val, cv = 5)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
